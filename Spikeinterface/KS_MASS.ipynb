{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76062c48-5eb1-4811-acfc-e25d580a1700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpikeGLXRecordingExtractor: 384 channels - 30.0kHz - 1 segments - 66,653,493 samples \n",
      "                            2,221.79s (37.03 minutes) - int16 dtype - 47.67 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepl\\anaconda3\\envs\\si_env\\lib\\site-packages\\spikeinterface\\preprocessing\\detect_bad_channels.py:216: UserWarning: Over 1/3 of channels are detected as bad. In the presence of a highnumber of dead / noisy channels, bad channel detection may fail (good channels may be erroneously labeled as dead).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted TTL event timestamps for bit 0 saved to ttl_0.csv\n",
      "Extracted TTL event timestamps for bit 1 saved to ttl_1.csv\n",
      "Extracted TTL event timestamps for bit 2 saved to ttl_2.csv\n",
      "['imec0.ap#AP26' 'imec0.ap#AP36' 'imec0.ap#AP169' 'imec0.ap#AP171'\n",
      " 'imec0.ap#AP173' 'imec0.ap#AP191']\n",
      "========================================\n",
      "Loading recording with SpikeInterface...\n",
      "number of samples: 66653493\n",
      "number of channels: 384\n",
      "numbef of segments: 1\n",
      "sampling rate: 29999.95593220339\n",
      "dtype: int16\n",
      "========================================\n",
      "Preprocessing filters computed in  283.51s; total  283.54s\n",
      "\n",
      "computing drift\n",
      "Re-computing universal templates from data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1111/1111 [2:04:41<00:00,  6.73s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift computed in  7717.94s; total  8001.52s\n",
      "\n",
      "Extracting spikes using templates\n",
      "Re-computing universal templates from data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1111/1111 [1:44:34<00:00,  5.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2479535 spikes extracted in  6505.69s; total  14507.21s\n",
      "\n",
      "First clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:56<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451 clusters found, in  57.56s; total  14564.77s\n",
      "\n",
      "Extracting spikes using cluster waveforms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1111/1111 [1:38:47<00:00,  5.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3678352 spikes extracted in  5928.06s; total  20492.83s\n",
      "\n",
      "Final clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:06<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444 clusters found, in  66.74s; total  20559.58s\n",
      "\n",
      "Merging clusters\n",
      "386 units found, in  3.24s; total  20562.81s\n",
      "\n",
      "Saving to phy and computing refractory periods\n",
      "94 units found with good refractory periods\n",
      "\n",
      "Total runtime: 20569.62s = 05:42:50 h:m:s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f7cf394d964a19b92e87f77df42bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "estimate_sparsity:   0%|          | 0/2222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c861953b9015452fb8e62818da324c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "compute_waveforms:   0%|          | 0/2222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99518b520c944d27a9f60cc5a4981de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spike_amplitudes:   0%|          | 0/2222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293147cf40804581bdbb33ed998fd2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting PCA:   0%|          | 0/386 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d5c20ca64741ed91b805e6334631af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Projecting waveforms:   0%|          | 0/386 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepl\\anaconda3\\envs\\si_env\\lib\\site-packages\\spikeinterface\\qualitymetrics\\misc_metrics.py:902: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf0ceee240e4c7d9f6477e7d9c55647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording:   0%|          | 0/2222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7795535d36db4ef6bcb90d99707306d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract PCs:   0%|          | 0/2222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  F:\\opto2\\M5685_2_g0\\sorted\\phy\\params.py\n",
      "SortingAnalyzer: 384 channels - 386 units - 1 segments - memory - sparse - has recording\n",
      "Loaded 9 extensions: random_spikes, waveforms, templates, noise_levels, unit_locations, correlograms, spike_amplitudes, principal_components, quality_metrics\n",
      "SortingAnalyzer: 384 channels - 196 units - 1 segments - binary_folder - sparse - has recording\n",
      "Loaded 10 extensions: random_spikes, waveforms, templates, noise_levels, unit_locations, correlograms, spike_amplitudes, principal_components, quality_metrics, template_similarity\n"
     ]
    }
   ],
   "source": [
    "import spikeinterface.full as si\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import probeinterface as pi\n",
    "from pathlib import Path\n",
    "import os \n",
    "import pandas as pd \n",
    "\n",
    "global_job_kwargs = dict(n_jobs=4, chunk_duration=\"1s\",progress_bar=True)\n",
    "si.set_global_job_kwargs(**global_job_kwargs)\n",
    "\n",
    "\n",
    "basefolder=\"F:/opto2/M5685_2_g0\"\n",
    "\n",
    "metapath = basefolder + str('/Meta')\n",
    "if not os.path.isdir(metapath):\n",
    "   os.makedirs(metapath)\n",
    "\n",
    "\n",
    "recording =  si.read_spikeglx(basefolder, stream_id='imec0.ap', load_sync_channel=False)\n",
    "lfp = si.read_spikeglx(basefolder, stream_id='imec0.lf', load_sync_channel=False)\n",
    "event =  si.read_spikeglx(basefolder, stream_id='nidq', load_sync_channel=False)\n",
    "\n",
    "print(recording)\n",
    "\n",
    "\n",
    "\n",
    "bad_channel_ids, channel_labels = si.detect_bad_channels(lfp,method = 'coherence+psd',outside_channels_location = 'both')\n",
    "names = lfp.channel_ids\n",
    "depth = lfp.get_channel_locations()[:,1]\n",
    "\n",
    "\n",
    "ar = pd.DataFrame({'name':names, 'depth':depth, 'labels':channel_labels})\n",
    "ar.to_csv(metapath + str('/lfp_labels.csv'))\n",
    "\n",
    "\n",
    "\n",
    "def extract_and_save_ttl_events(data, bits, save_path):\n",
    "    digital_signals = data.get_traces()\n",
    "    digital_word = digital_signals[:, 0]\n",
    "    sampling_rate = data.get_sampling_frequency()\n",
    "    for bit in bits:\n",
    "        # Extract TTL pulses for the current bit\n",
    "        ttl_timestamps = extract_ttl_from_bit(digital_word, bit, sampling_rate)\n",
    "        \n",
    "        ttl_df = pd.DataFrame(ttl_timestamps, columns=['timestamps'])\n",
    "        \n",
    "        filename = f'ttl_{bit}.csv'\n",
    "        \n",
    "        ttl_df.to_csv(f\"{save_path}/{filename}\", index=False)\n",
    "        print(f\"Extracted TTL event timestamps for bit {bit} saved to {filename}\")\n",
    "\n",
    "\n",
    "def extract_ttl_from_bit(digital_word, bit, sampling_rate):\n",
    "    # Extract the specific bit from the word (bit-shifting and masking)\n",
    "    ttl_signal = (digital_word >> bit) & 1  # Right shift and mask to isolate the specific bit\n",
    "    \n",
    "    # Detect rising edges (0 -> 1 transitions)\n",
    "    ttl_rising_edges = np.where(np.diff(ttl_signal) > 0)[0]\n",
    "    \n",
    "    # Convert sample indices to timestamps (in seconds)\n",
    "    ttl_timestamps = ttl_rising_edges / sampling_rate\n",
    "    \n",
    "    return ttl_timestamps\n",
    "\n",
    "\n",
    "bits_to_extract = [0, 1, 2]  \n",
    "extract_and_save_ttl_events(event , bits_to_extract, metapath)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rec1 = si.highpass_filter(recording, freq_min=400.)\n",
    "rec1 = si.phase_shift(rec1)\n",
    "bad_channel_ids, channel_labels = si.detect_bad_channels(rec1,method = 'coherence+psd')\n",
    "print(bad_channel_ids)\n",
    "rec1 = si.interpolate_bad_channels(recording=rec1, bad_channel_ids=bad_channel_ids)\n",
    "\n",
    "rec1 = si.common_reference(rec1, operator=\"median\", reference=\"global\")\n",
    "\n",
    "\n",
    "Sorting_KS4 = si.run_sorter(sorter_name=\"kilosort4\", recording=rec1, folder=basefolder + str('/sorted'),remove_existing_folder=True)\n",
    "\n",
    "analyzer = si.create_sorting_analyzer(Sorting_KS4, rec1, sparse=True, format=\"memory\")\n",
    "\n",
    "analyzer.compute(['random_spikes', 'waveforms', 'templates', 'noise_levels','unit_locations','correlograms'],**global_job_kwargs)\n",
    "analyzer.compute('spike_amplitudes')\n",
    "analyzer.compute('principal_components', n_components = 5, mode=\"by_channel_local\",**global_job_kwargs)\n",
    "\n",
    "metric_names=['firing_rate', 'presence_ratio', 'snr','isi_violation', 'amplitude_cutoff']\n",
    "metrics = si.compute_quality_metrics(analyzer, metric_names=metric_names)\n",
    "\n",
    "\n",
    "amplitude_cutoff_thresh = 0.1\n",
    "isi_violations_ratio_thresh = 0.5\n",
    "presence_ratio_thresh = 0.9\n",
    "\n",
    "\n",
    "our_query = f\"(amplitude_cutoff < {amplitude_cutoff_thresh}) & (isi_violations_ratio < {isi_violations_ratio_thresh}) & (presence_ratio > {presence_ratio_thresh})\"\n",
    "\n",
    "keep_units = metrics.query(our_query)\n",
    "keep_unit_ids = keep_units.index.values\n",
    "analyzer_clean = analyzer.select_units(keep_unit_ids, folder=basefolder +str('/analyzer_clean'), format='binary_folder')\n",
    "\n",
    "si.export_to_phy(analyzer_clean, output_folder=basefolder + str('/sorted/phy'),**global_job_kwargs)\n",
    "\n",
    "print(analyzer)\n",
    "print(analyzer_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121e5da8-7614-4447-92b5-1ac25e82ecdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bd1e09-b8ee-48e5-af6c-c6eb5de81b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "!phy template-gui F:\\copydaya\\M9_2\\sorted\\phy\\params.py\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
