{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f65dbace-bd24-42a8-a166-2653dd1d8c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import probeinterface as pi\n",
    "from pathlib import Path\n",
    "import os \n",
    "import pandas as pd \n",
    "\n",
    "global_job_kwargs = dict(n_jobs=4, chunk_duration=\"1s\",progress_bar=True)\n",
    "si.set_global_job_kwargs(**global_job_kwargs)\n",
    "\n",
    "\n",
    "basefolder=\"D:/M8_SNA-135381_17092024_1_g0_imec1\"\n",
    "\n",
    "metapath = basefolder + str('/Meta')\n",
    "if not os.path.isdir(metapath):\n",
    "   os.makedirs(metapath)\n",
    "\n",
    "\n",
    "recording =  si.read_spikeglx(basefolder, stream_id='imec1.ap', load_sync_channel=False)\n",
    "lfp = si.read_spikeglx(basefolder, stream_id='imec1.lf', load_sync_channel=False)\n",
    "event =  si.read_spikeglx(basefolder, stream_id='nidq', load_sync_channel=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bad_channel_ids, channel_labels = si.detect_bad_channels(lfp,method = 'coherence+psd',outside_channels_location = 'both')\n",
    "names = lfp.channel_ids\n",
    "depth = lfp.get_channel_locations()[:,1]\n",
    "\n",
    "\n",
    "ar = pd.DataFrame({'name':names, 'depth':depth, 'labels':channel_labels})\n",
    "ar.to_csv(metapath + str('/lfp_labels.csv'))\n",
    "\n",
    "\n",
    "\n",
    "def extract_and_save_ttl_events(data, bits, save_path):\n",
    "    digital_signals = data.get_traces()\n",
    "    digital_word = digital_signals[:, 0]\n",
    "    sampling_rate = data.get_sampling_frequency()\n",
    "    for bit in bits:\n",
    "        # Extract TTL pulses for the current bit\n",
    "        ttl_timestamps = extract_ttl_from_bit(digital_word, bit, sampling_rate)\n",
    "        \n",
    "        ttl_df = pd.DataFrame(ttl_timestamps, columns=['timestamps'])\n",
    "        \n",
    "        filename = f'ttl_{bit}.csv'\n",
    "        \n",
    "        ttl_df.to_csv(f\"{save_path}/{filename}\", index=False)\n",
    "        print(f\"Extracted TTL event timestamps for bit {bit} saved to {filename}\")\n",
    "\n",
    "\n",
    "def extract_ttl_from_bit(digital_word, bit, sampling_rate):\n",
    "    # Extract the specific bit from the word (bit-shifting and masking)\n",
    "    ttl_signal = (digital_word >> bit) & 1  # Right shift and mask to isolate the specific bit\n",
    "    \n",
    "    # Detect rising edges (0 -> 1 transitions)\n",
    "    ttl_rising_edges = np.where(np.diff(ttl_signal) > 0)[0]\n",
    "    \n",
    "    # Convert sample indices to timestamps (in seconds)\n",
    "    ttl_timestamps = ttl_rising_edges / sampling_rate\n",
    "    \n",
    "    return ttl_timestamps\n",
    "\n",
    "\n",
    "bits_to_extract = [0, 1, 2]  \n",
    "extract_and_save_ttl_events(event , bits_to_extract, metapath)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rec1 = si.highpass_filter(recording, freq_min=400.)\n",
    "rec1 = si.phase_shift(rec1)\n",
    "bad_channel_ids, channel_labels = si.detect_bad_channels(rec1,method = 'coherence+psd')\n",
    "print(bad_channel_ids)\n",
    "rec1 = si.interpolate_bad_channels(recording=rec1, bad_channel_ids=bad_channel_ids)\n",
    "\n",
    "rec1 = si.common_reference(rec1, operator=\"median\", reference=\"global\")\n",
    "\n",
    "\n",
    "Sorting_KS4 = si.run_sorter(sorter_name=\"kilosort4\", recording=rec1, folder=basefolder + str('/sorted'),remove_existing_folder=True)\n",
    "\n",
    "analyzer = si.create_sorting_analyzer(Sorting_KS4, rec1, sparse=True, format=\"memory\")\n",
    "\n",
    "analyzer.compute(['random_spikes', 'waveforms', 'templates', 'noise_levels','unit_locations','correlograms'],**global_job_kwargs)\n",
    "analyzer.compute('spike_amplitudes')\n",
    "analyzer.compute('principal_components', n_components = 5, mode=\"by_channel_local\",**global_job_kwargs)\n",
    "\n",
    "metric_names=['firing_rate', 'presence_ratio', 'snr','isi_violation', 'amplitude_cutoff']\n",
    "metrics = si.compute_quality_metrics(analyzer, metric_names=metric_names)\n",
    "\n",
    "\n",
    "amplitude_cutoff_thresh = 0.1\n",
    "isi_violations_ratio_thresh = 0.5\n",
    "presence_ratio_thresh = 0.9\n",
    "\n",
    "\n",
    "our_query = f\"(amplitude_cutoff < {amplitude_cutoff_thresh}) & (isi_violations_ratio < {isi_violations_ratio_thresh}) & (presence_ratio > {presence_ratio_thresh})\"\n",
    "\n",
    "keep_units = metrics.query(our_query)\n",
    "keep_unit_ids = keep_units.index.values\n",
    "analyzer_clean = analyzer.select_units(keep_unit_ids, folder=basefolder +str('/analyzer_clean'), format='binary_folder')\n",
    "\n",
    "si.export_to_phy(analyzer_clean, output_folder=basefolder + str('/sorted/phy'),**global_job_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23bd1e09-b8ee-48e5-af6c-c6eb5de81b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m15:14:23.038 [W] model:667            Skipping spike waveforms that do not exist, they will be extracted on the fly from the raw data as needed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!phy template-gui  E:\\Florian\\test\\params.py\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
